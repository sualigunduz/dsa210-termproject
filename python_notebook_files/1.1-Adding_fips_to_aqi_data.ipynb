{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Pandas, the only library needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the datasets for the FIPS codes the Air Quality Index data for each county.\n",
    "\n",
    "FIPS (Federal Information Processing Standards) codes are a system designed by the main standards agency of the United States Government, the National Institute of Standards and Technology (NIST). Each location in the United States, whether it is a state, county, city, metro area is assigned a specific code. These codes are especially useful when we need to combine different location-specific data. County FIPS codes are 5 digits. Only the AQI data doesn't have them in this project so we'll need to add it by hand.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Year</th>\n",
       "      <th>Days with AQI</th>\n",
       "      <th>Good Days</th>\n",
       "      <th>Moderate Days</th>\n",
       "      <th>Unhealthy for Sensitive Groups Days</th>\n",
       "      <th>Unhealthy Days</th>\n",
       "      <th>Very Unhealthy Days</th>\n",
       "      <th>Hazardous Days</th>\n",
       "      <th>Max AQI</th>\n",
       "      <th>90th Percentile AQI</th>\n",
       "      <th>Median AQI</th>\n",
       "      <th>Days CO</th>\n",
       "      <th>Days NO2</th>\n",
       "      <th>Days Ozone</th>\n",
       "      <th>Days PM2.5</th>\n",
       "      <th>Days PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2019</td>\n",
       "      <td>271</td>\n",
       "      <td>221</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Clay</td>\n",
       "      <td>2019</td>\n",
       "      <td>107</td>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Colbert</td>\n",
       "      <td>2019</td>\n",
       "      <td>263</td>\n",
       "      <td>238</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>DeKalb</td>\n",
       "      <td>2019</td>\n",
       "      <td>361</td>\n",
       "      <td>303</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Elmore</td>\n",
       "      <td>2019</td>\n",
       "      <td>228</td>\n",
       "      <td>208</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State   County  Year  Days with AQI  Good Days  Moderate Days  \\\n",
       "0  Alabama  Baldwin  2019            271        221             50   \n",
       "1  Alabama     Clay  2019            107         75             32   \n",
       "2  Alabama  Colbert  2019            263        238             25   \n",
       "3  Alabama   DeKalb  2019            361        303             58   \n",
       "4  Alabama   Elmore  2019            228        208             20   \n",
       "\n",
       "   Unhealthy for Sensitive Groups Days  Unhealthy Days  Very Unhealthy Days  \\\n",
       "0                                    0               0                    0   \n",
       "1                                    0               0                    0   \n",
       "2                                    0               0                    0   \n",
       "3                                    0               0                    0   \n",
       "4                                    0               0                    0   \n",
       "\n",
       "   Hazardous Days  Max AQI  90th Percentile AQI  Median AQI  Days CO  \\\n",
       "0               0       80                   55          40        0   \n",
       "1               0       71                   56          41        0   \n",
       "2               0       65                   50          38        0   \n",
       "3               0       90                   54          39        0   \n",
       "4               0      100                   50          39        0   \n",
       "\n",
       "   Days NO2  Days Ozone  Days PM2.5  Days PM10  \n",
       "0         0         198          73          0  \n",
       "1         0           0         107          0  \n",
       "2         0         219          44          0  \n",
       "3         0         306          55          0  \n",
       "4         0         228           0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading FIPS data\n",
    "fips_df = pd.read_csv(\"FIPS_DATA_State__County_and_City_FIPS_Reference_Table_20250413.csv\", dtype={\"StCnty FIPS Code\": str})[:-2]\n",
    "\n",
    "# Loading AQI (target) data\n",
    "aqi_df = pd.read_csv(\"AIR_annual_aqi_by_county_2019.csv\")\n",
    "\n",
    "aqi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reducing the FIPS data to only the variables necessary and dropping duplicates\n",
    "Since the FIPS dataset has a row entry for each settlement inside a county which is not necessary for this project. In the end we'll have a unique row for each county instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Name</th>\n",
       "      <th>County Name</th>\n",
       "      <th>StCnty FIPS Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AUTAUGA</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>BALDWIN</td>\n",
       "      <td>01003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>BARBOUR</td>\n",
       "      <td>01005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>BIBB</td>\n",
       "      <td>01007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>BLOUNT</td>\n",
       "      <td>01009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State Name County Name StCnty FIPS Code\n",
       "0     ALABAMA     AUTAUGA            01001\n",
       "6     ALABAMA     BALDWIN            01003\n",
       "30    ALABAMA     BARBOUR            01005\n",
       "38    ALABAMA        BIBB            01007\n",
       "47    ALABAMA      BLOUNT            01009"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce FIPS data to only necessary variables\n",
    "fips_subset = fips_df[[\"State Name\", \"County Name\", \"StCnty FIPS Code\"]]\n",
    "\n",
    "# Drop duplicates\n",
    "fips_dedup = fips_subset.drop_duplicates(subset=[\"State Name\", \"County Name\"])\n",
    "\n",
    "fips_dedup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \"Cleaning\" names\n",
    "We strip and convert all characters to uppercase in the state and county names for both datasets so that we can match them easily afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_17860\\3215889540.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fips_dedup['State_clean'] = fips_dedup['State Name'].apply(clean_name)\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_17860\\3215889540.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fips_dedup['County_clean'] = fips_dedup['County Name'].apply(clean_name)\n"
     ]
    }
   ],
   "source": [
    "# Turning everything to same character format\n",
    "clean_name = lambda x : x.strip().upper()\n",
    "\n",
    "# Apply the cleaning function to Dataset 1 (FIPS data)\n",
    "fips_dedup['State_clean'] = fips_dedup['State Name'].apply(clean_name)\n",
    "fips_dedup['County_clean'] = fips_dedup['County Name'].apply(clean_name)\n",
    "\n",
    "# Apply the cleaning function to Dataset 2 (Target data)\n",
    "aqi_df['State_clean'] = aqi_df['State'].apply(clean_name)\n",
    "aqi_df['County_clean'] = aqi_df['County'].apply(clean_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Merging datasets on state and county names.\n",
    "We merge the datasets on both state and county names since there are multiple counties with the same name across different states, though there aren't any same-named counties within a single state.\n",
    "\n",
    "Most of them are named after former presidents: 24 counties are called \"Lincoln\", 25 counties are called \"Franklin\", 26 counties are called \"Jefferson\" and 31 counties are called \"Washington\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on both cleaned state and county names\n",
    "merged_df = pd.merge(aqi_df, \n",
    "                     fips_dedup, \n",
    "                     left_on=['State_clean', 'County_clean'], \n",
    "                     right_on=['State_clean', 'County_clean'], \n",
    "                     how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Cleaning the final dataframe\n",
    "\n",
    "The resulting merged dataframe has its unnecessary columns dropped, its column order reorganized for better readability and the FIPS code is converted to a string type because some FIPS codes have a leading zero which Python can't handle in integer form. Finally, the dataframe is converted to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "merged_df = merged_df.drop(columns=[\n",
    "    'State_clean', 'County_clean', 'State Name', 'County Name'\n",
    "])\n",
    "\n",
    "# Move 'StCnty FIPS Code' between 'County' and 'Year'\n",
    "cols = merged_df.columns.tolist()\n",
    "cols.remove('StCnty FIPS Code')\n",
    "insert_position = cols.index('Year')  # Insert before 'Year'\n",
    "cols.insert(insert_position, 'StCnty FIPS Code')\n",
    "\n",
    "# Reorder DataFrame\n",
    "merged_df = merged_df[cols]\n",
    "\n",
    "merged_df['StCnty FIPS Code'] = merged_df['StCnty FIPS Code'].astype(str)\n",
    "\n",
    "# Check the result to ensure the merge worked as expected\n",
    "merged_df.to_csv('AIR_DATA_WITH_FIPS.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSA201",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
